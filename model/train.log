Sat, 03 Nov 2018 16:32:28 train.py[line:109] INFO Model Save directory already exists.
Sat, 03 Nov 2018 16:38:47 train.py[line:109] INFO Model Save directory already exists.
Sat, 03 Nov 2018 16:39:40 train.py[line:109] INFO Model Save directory already exists.
Sat, 03 Nov 2018 16:39:45 train.py[line:174] INFO DataParallel(
  (module): DeepSpeech(
    (conv): Sequential(
      (0): Conv2d(1, 32, kernel_size=(41, 11), stride=(2, 2), padding=(0, 10))
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): Hardtanh(min_val=0, max_val=20, inplace)
      (3): Conv2d(32, 32, kernel_size=(21, 11), stride=(2, 1))
      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): Hardtanh(min_val=0, max_val=20, inplace)
    )
    (rnns): Sequential(
      (0): BatchRNN(
        (rnn): GRU(672, 800, bias=False, bidirectional=True)
      )
      (1): BatchRNN(
        (batch_norm): SequenceWise (
        BatchNorm1d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True))
        (rnn): GRU(800, 800, bias=False, bidirectional=True)
      )
      (2): BatchRNN(
        (batch_norm): SequenceWise (
        BatchNorm1d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True))
        (rnn): GRU(800, 800, bias=False, bidirectional=True)
      )
      (3): BatchRNN(
        (batch_norm): SequenceWise (
        BatchNorm1d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True))
        (rnn): GRU(800, 800, bias=False, bidirectional=True)
      )
      (4): BatchRNN(
        (batch_norm): SequenceWise (
        BatchNorm1d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True))
        (rnn): GRU(800, 800, bias=False, bidirectional=True)
      )
    )
    (fc): Sequential(
      (0): SequenceWise (
      Sequential(
        (0): BatchNorm1d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (1): Linear(in_features=800, out_features=6276, bias=False)
      ))
    )
    (inference_softmax): InferenceBatchSoftmax()
  )
)
Sat, 03 Nov 2018 16:39:45 train.py[line:175] INFO Number of parameters: 43065568
Sat, 03 Nov 2018 16:39:48 train.py[line:227] INFO Epoch: [1][1/1]	Time 2.885 (2.885)	Data 0.000 (0.000)	Loss 2000.9788 (2000.9788)	
Sat, 03 Nov 2018 16:39:48 train.py[line:236] INFO Training Summary Epoch: [1]	Time taken (s): 3	Average Loss 2000.979	
Sat, 03 Nov 2018 16:39:50 train.py[line:271] INFO Validation Summary Epoch: [1]	Average CER 485.880	
Sat, 03 Nov 2018 16:39:50 train.py[line:282] INFO Learning rate annealed to: 0.000273
Sat, 03 Nov 2018 16:39:50 train.py[line:285] INFO Found better validated model, saving to model/model.pth
Sat, 03 Nov 2018 16:39:50 train.py[line:291] INFO Shuffling batches...
Sat, 03 Nov 2018 16:39:53 train.py[line:227] INFO Epoch: [2][1/1]	Time 2.412 (2.649)	Data 0.000 (0.000)	Loss 1893.8177 (1947.3983)	
Sat, 03 Nov 2018 16:39:53 train.py[line:236] INFO Training Summary Epoch: [2]	Time taken (s): 3	Average Loss 1893.818	
Sat, 03 Nov 2018 16:39:55 train.py[line:271] INFO Validation Summary Epoch: [2]	Average CER 158.005	
Sat, 03 Nov 2018 16:39:55 train.py[line:282] INFO Learning rate annealed to: 0.000248
Sat, 03 Nov 2018 16:39:55 train.py[line:285] INFO Found better validated model, saving to model/model.pth
Sat, 03 Nov 2018 16:39:56 train.py[line:291] INFO Shuffling batches...
Sat, 03 Nov 2018 16:39:59 train.py[line:227] INFO Epoch: [3][1/1]	Time 2.544 (2.614)	Data 0.000 (0.000)	Loss 1618.6824 (1837.8263)	
Sat, 03 Nov 2018 16:39:59 train.py[line:236] INFO Training Summary Epoch: [3]	Time taken (s): 3	Average Loss 1618.682	
Sat, 03 Nov 2018 16:40:00 train.py[line:271] INFO Validation Summary Epoch: [3]	Average CER 100.000	
Sat, 03 Nov 2018 16:40:00 train.py[line:282] INFO Learning rate annealed to: 0.000225
Sat, 03 Nov 2018 16:40:00 train.py[line:285] INFO Found better validated model, saving to model/model.pth
Sat, 03 Nov 2018 16:40:02 train.py[line:291] INFO Shuffling batches...
Sat, 03 Nov 2018 16:40:04 train.py[line:227] INFO Epoch: [4][1/1]	Time 2.464 (2.576)	Data 0.000 (0.000)	Loss 1208.3837 (1680.4656)	
Sat, 03 Nov 2018 16:40:04 train.py[line:236] INFO Training Summary Epoch: [4]	Time taken (s): 3	Average Loss 1208.384	
Sat, 03 Nov 2018 16:40:06 train.py[line:271] INFO Validation Summary Epoch: [4]	Average CER 100.000	
Sat, 03 Nov 2018 16:40:06 train.py[line:282] INFO Learning rate annealed to: 0.000205
Sat, 03 Nov 2018 16:40:06 train.py[line:291] INFO Shuffling batches...
Sat, 03 Nov 2018 16:40:09 train.py[line:227] INFO Epoch: [5][1/1]	Time 2.428 (2.547)	Data 0.000 (0.000)	Loss 824.9071 (1509.3539)	
Sat, 03 Nov 2018 16:40:09 train.py[line:236] INFO Training Summary Epoch: [5]	Time taken (s): 3	Average Loss 824.907	
Sat, 03 Nov 2018 16:40:10 train.py[line:271] INFO Validation Summary Epoch: [5]	Average CER 100.000	
Sat, 03 Nov 2018 16:40:10 train.py[line:282] INFO Learning rate annealed to: 0.000186
Sat, 03 Nov 2018 16:40:10 train.py[line:291] INFO Shuffling batches...
Sat, 03 Nov 2018 16:40:13 train.py[line:227] INFO Epoch: [6][1/1]	Time 2.555 (2.548)	Data 0.000 (0.000)	Loss 438.5241 (1330.8823)	
Sat, 03 Nov 2018 16:40:13 train.py[line:236] INFO Training Summary Epoch: [6]	Time taken (s): 3	Average Loss 438.524	
Sat, 03 Nov 2018 16:40:15 train.py[line:271] INFO Validation Summary Epoch: [6]	Average CER 100.000	
Sat, 03 Nov 2018 16:40:15 train.py[line:282] INFO Learning rate annealed to: 0.000169
Sat, 03 Nov 2018 16:40:15 train.py[line:291] INFO Shuffling batches...
Sat, 03 Nov 2018 16:40:17 train.py[line:227] INFO Epoch: [7][1/1]	Time 2.516 (2.543)	Data 0.000 (0.000)	Loss 184.9684 (1167.1803)	
Sat, 03 Nov 2018 16:40:17 train.py[line:236] INFO Training Summary Epoch: [7]	Time taken (s): 3	Average Loss 184.968	
Sat, 03 Nov 2018 16:40:19 train.py[line:271] INFO Validation Summary Epoch: [7]	Average CER 100.000	
Sat, 03 Nov 2018 16:40:19 train.py[line:282] INFO Learning rate annealed to: 0.000154
Sat, 03 Nov 2018 16:40:19 train.py[line:291] INFO Shuffling batches...
Sat, 03 Nov 2018 16:40:22 train.py[line:227] INFO Epoch: [8][1/1]	Time 2.732 (2.567)	Data 0.000 (0.000)	Loss 135.1774 (1038.1799)	
Sat, 03 Nov 2018 16:40:22 train.py[line:236] INFO Training Summary Epoch: [8]	Time taken (s): 3	Average Loss 135.177	
Sat, 03 Nov 2018 16:40:24 train.py[line:271] INFO Validation Summary Epoch: [8]	Average CER 100.000	
Sat, 03 Nov 2018 16:40:24 train.py[line:282] INFO Learning rate annealed to: 0.000140
Sat, 03 Nov 2018 16:40:24 train.py[line:291] INFO Shuffling batches...
Sat, 03 Nov 2018 16:40:27 train.py[line:227] INFO Epoch: [9][1/1]	Time 2.424 (2.551)	Data 0.000 (0.000)	Loss 135.5600 (937.8888)	
Sat, 03 Nov 2018 16:40:27 train.py[line:236] INFO Training Summary Epoch: [9]	Time taken (s): 3	Average Loss 135.560	
Sat, 03 Nov 2018 16:40:28 train.py[line:271] INFO Validation Summary Epoch: [9]	Average CER 100.000	
Sat, 03 Nov 2018 16:40:28 train.py[line:282] INFO Learning rate annealed to: 0.000127
Sat, 03 Nov 2018 16:40:28 train.py[line:291] INFO Shuffling batches...
Sat, 03 Nov 2018 16:40:31 train.py[line:227] INFO Epoch: [10][1/1]	Time 2.528 (2.549)	Data 0.000 (0.000)	Loss 147.9961 (858.8996)	
Sat, 03 Nov 2018 16:40:31 train.py[line:236] INFO Training Summary Epoch: [10]	Time taken (s): 3	Average Loss 147.996	
Sat, 03 Nov 2018 16:40:33 train.py[line:271] INFO Validation Summary Epoch: [10]	Average CER 100.000	
Sat, 03 Nov 2018 16:40:33 train.py[line:282] INFO Learning rate annealed to: 0.000116
Sat, 03 Nov 2018 16:40:33 train.py[line:291] INFO Shuffling batches...
Sat, 03 Nov 2018 16:40:36 train.py[line:227] INFO Epoch: [11][1/1]	Time 2.518 (2.546)	Data 0.000 (0.000)	Loss 138.6775 (793.4248)	
Sat, 03 Nov 2018 16:40:36 train.py[line:236] INFO Training Summary Epoch: [11]	Time taken (s): 3	Average Loss 138.677	
Sat, 03 Nov 2018 16:40:37 train.py[line:271] INFO Validation Summary Epoch: [11]	Average CER 99.091	
Sat, 03 Nov 2018 16:40:37 train.py[line:282] INFO Learning rate annealed to: 0.000105
Sat, 03 Nov 2018 16:40:37 train.py[line:285] INFO Found better validated model, saving to model/model.pth
Sat, 03 Nov 2018 16:40:39 train.py[line:291] INFO Shuffling batches...
Sat, 03 Nov 2018 16:40:41 train.py[line:227] INFO Epoch: [12][1/1]	Time 2.555 (2.547)	Data 0.000 (0.000)	Loss 135.9739 (738.6373)	
Sat, 03 Nov 2018 16:40:41 train.py[line:236] INFO Training Summary Epoch: [12]	Time taken (s): 3	Average Loss 135.974	
Sat, 03 Nov 2018 16:40:43 train.py[line:271] INFO Validation Summary Epoch: [12]	Average CER 99.091	
Sat, 03 Nov 2018 16:40:43 train.py[line:282] INFO Learning rate annealed to: 0.000096
Sat, 03 Nov 2018 16:40:43 train.py[line:291] INFO Shuffling batches...
Sat, 03 Nov 2018 16:40:46 train.py[line:227] INFO Epoch: [13][1/1]	Time 2.492 (2.543)	Data 0.000 (0.000)	Loss 137.8893 (692.4259)	
Sat, 03 Nov 2018 16:40:46 train.py[line:236] INFO Training Summary Epoch: [13]	Time taken (s): 3	Average Loss 137.889	
Sat, 03 Nov 2018 16:40:47 train.py[line:271] INFO Validation Summary Epoch: [13]	Average CER 98.944	
Sat, 03 Nov 2018 16:40:47 train.py[line:282] INFO Learning rate annealed to: 0.000087
Sat, 03 Nov 2018 16:40:47 train.py[line:285] INFO Found better validated model, saving to model/model.pth
Sat, 03 Nov 2018 16:40:48 train.py[line:291] INFO Shuffling batches...
Sat, 03 Nov 2018 16:40:51 train.py[line:227] INFO Epoch: [14][1/1]	Time 2.442 (2.535)	Data 0.000 (0.000)	Loss 132.4626 (652.4285)	
Sat, 03 Nov 2018 16:40:51 train.py[line:236] INFO Training Summary Epoch: [14]	Time taken (s): 3	Average Loss 132.463	
Sat, 03 Nov 2018 16:40:53 train.py[line:271] INFO Validation Summary Epoch: [14]	Average CER 98.444	
Sat, 03 Nov 2018 16:40:53 train.py[line:282] INFO Learning rate annealed to: 0.000079
Sat, 03 Nov 2018 16:40:53 train.py[line:285] INFO Found better validated model, saving to model/model.pth
Sat, 03 Nov 2018 16:40:54 train.py[line:291] INFO Shuffling batches...
Sat, 03 Nov 2018 16:40:57 train.py[line:227] INFO Epoch: [15][1/1]	Time 2.510 (2.534)	Data 0.000 (0.000)	Loss 129.7743 (617.5849)	
Sat, 03 Nov 2018 16:40:57 train.py[line:236] INFO Training Summary Epoch: [15]	Time taken (s): 3	Average Loss 129.774	
Sat, 03 Nov 2018 16:40:58 train.py[line:271] INFO Validation Summary Epoch: [15]	Average CER 98.444	
Sat, 03 Nov 2018 16:40:58 train.py[line:282] INFO Learning rate annealed to: 0.000072
Sat, 03 Nov 2018 16:40:58 train.py[line:291] INFO Shuffling batches...
Sat, 03 Nov 2018 16:41:01 train.py[line:227] INFO Epoch: [16][1/1]	Time 2.427 (2.527)	Data 0.000 (0.000)	Loss 129.0676 (587.0526)	
Sat, 03 Nov 2018 16:41:01 train.py[line:236] INFO Training Summary Epoch: [16]	Time taken (s): 3	Average Loss 129.068	
Sat, 03 Nov 2018 16:41:03 train.py[line:271] INFO Validation Summary Epoch: [16]	Average CER 98.444	
Sat, 03 Nov 2018 16:41:03 train.py[line:282] INFO Learning rate annealed to: 0.000065
Sat, 03 Nov 2018 16:41:03 train.py[line:291] INFO Shuffling batches...
Sat, 03 Nov 2018 16:41:06 train.py[line:227] INFO Epoch: [17][1/1]	Time 2.547 (2.528)	Data 0.000 (0.000)	Loss 127.3237 (560.0097)	
Sat, 03 Nov 2018 16:41:06 train.py[line:236] INFO Training Summary Epoch: [17]	Time taken (s): 3	Average Loss 127.324	
Sat, 03 Nov 2018 16:41:07 train.py[line:271] INFO Validation Summary Epoch: [17]	Average CER 98.444	
Sat, 03 Nov 2018 16:41:07 train.py[line:282] INFO Learning rate annealed to: 0.000059
Sat, 03 Nov 2018 16:41:07 train.py[line:291] INFO Shuffling batches...
Sat, 03 Nov 2018 16:41:10 train.py[line:227] INFO Epoch: [18][1/1]	Time 2.572 (2.531)	Data 0.000 (0.000)	Loss 125.1605 (535.8514)	
Sat, 03 Nov 2018 16:41:10 train.py[line:236] INFO Training Summary Epoch: [18]	Time taken (s): 3	Average Loss 125.160	
Sat, 03 Nov 2018 16:41:12 train.py[line:271] INFO Validation Summary Epoch: [18]	Average CER 98.444	
Sat, 03 Nov 2018 16:41:12 train.py[line:282] INFO Learning rate annealed to: 0.000054
Sat, 03 Nov 2018 16:41:12 train.py[line:291] INFO Shuffling batches...
Sat, 03 Nov 2018 18:24:01 train.py[line:109] INFO Model Save directory already exists.
Sat, 03 Nov 2018 18:24:01 train.py[line:115] INFO Loading checkpoint model model/model.pth
Sat, 03 Nov 2018 18:24:06 train.py[line:170] INFO Shuffling batches for the following epochs
Sat, 03 Nov 2018 18:24:06 train.py[line:174] INFO DataParallel(
  (module): DeepSpeech(
    (conv): Sequential(
      (0): Conv2d(1, 32, kernel_size=(41, 11), stride=(2, 2), padding=(0, 10))
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): Hardtanh(min_val=0, max_val=20, inplace)
      (3): Conv2d(32, 32, kernel_size=(21, 11), stride=(2, 1))
      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): Hardtanh(min_val=0, max_val=20, inplace)
    )
    (rnns): Sequential(
      (0): BatchRNN(
        (rnn): GRU(672, 800, bias=False, bidirectional=True)
      )
      (1): BatchRNN(
        (batch_norm): SequenceWise (
        BatchNorm1d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True))
        (rnn): GRU(800, 800, bias=False, bidirectional=True)
      )
      (2): BatchRNN(
        (batch_norm): SequenceWise (
        BatchNorm1d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True))
        (rnn): GRU(800, 800, bias=False, bidirectional=True)
      )
      (3): BatchRNN(
        (batch_norm): SequenceWise (
        BatchNorm1d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True))
        (rnn): GRU(800, 800, bias=False, bidirectional=True)
      )
      (4): BatchRNN(
        (batch_norm): SequenceWise (
        BatchNorm1d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True))
        (rnn): GRU(800, 800, bias=False, bidirectional=True)
      )
    )
    (fc): Sequential(
      (0): SequenceWise (
      Sequential(
        (0): BatchNorm1d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (1): Linear(in_features=800, out_features=6276, bias=False)
      ))
    )
    (inference_softmax): InferenceBatchSoftmax()
  )
)
Sat, 03 Nov 2018 18:24:06 train.py[line:175] INFO Number of parameters: 43065568
Sat, 03 Nov 2018 18:24:42 train.py[line:109] INFO Model Save directory already exists.
Sat, 03 Nov 2018 18:24:42 train.py[line:115] INFO Loading checkpoint model model/model.pth
Sat, 03 Nov 2018 18:24:48 train.py[line:170] INFO Shuffling batches for the following epochs
Sat, 03 Nov 2018 18:24:48 train.py[line:174] INFO DataParallel(
  (module): DeepSpeech(
    (conv): Sequential(
      (0): Conv2d(1, 32, kernel_size=(41, 11), stride=(2, 2), padding=(0, 10))
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): Hardtanh(min_val=0, max_val=20, inplace)
      (3): Conv2d(32, 32, kernel_size=(21, 11), stride=(2, 1))
      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): Hardtanh(min_val=0, max_val=20, inplace)
    )
    (rnns): Sequential(
      (0): BatchRNN(
        (rnn): GRU(672, 800, bias=False, bidirectional=True)
      )
      (1): BatchRNN(
        (batch_norm): SequenceWise (
        BatchNorm1d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True))
        (rnn): GRU(800, 800, bias=False, bidirectional=True)
      )
      (2): BatchRNN(
        (batch_norm): SequenceWise (
        BatchNorm1d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True))
        (rnn): GRU(800, 800, bias=False, bidirectional=True)
      )
      (3): BatchRNN(
        (batch_norm): SequenceWise (
        BatchNorm1d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True))
        (rnn): GRU(800, 800, bias=False, bidirectional=True)
      )
      (4): BatchRNN(
        (batch_norm): SequenceWise (
        BatchNorm1d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True))
        (rnn): GRU(800, 800, bias=False, bidirectional=True)
      )
    )
    (fc): Sequential(
      (0): SequenceWise (
      Sequential(
        (0): BatchNorm1d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (1): Linear(in_features=800, out_features=6276, bias=False)
      ))
    )
    (inference_softmax): InferenceBatchSoftmax()
  )
)
Sat, 03 Nov 2018 18:24:48 train.py[line:175] INFO Number of parameters: 43065568
Sat, 03 Nov 2018 18:24:52 train.py[line:227] INFO Epoch: [14][1/1]	Time 2.777 (2.777)	Data 0.000 (0.000)	Loss 133.0517 (133.0517)	
Sat, 03 Nov 2018 18:24:52 train.py[line:236] INFO Training Summary Epoch: [14]	Time taken (s): 4	Average Loss 133.052	
Sat, 03 Nov 2018 18:24:53 train.py[line:271] INFO Validation Summary Epoch: [14]	Average CER 98.444	
Sat, 03 Nov 2018 18:24:53 train.py[line:282] INFO Learning rate annealed to: 0.000072
Sat, 03 Nov 2018 18:24:53 train.py[line:285] INFO Found better validated model, saving to model/model.pth
Sat, 03 Nov 2018 18:24:55 train.py[line:291] INFO Shuffling batches...
